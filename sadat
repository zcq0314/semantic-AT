
def build_char2word(sent_text: str):
    spans = list(jieba.tokenize(sent_text))  # [(word, start, end), ...]
    char2word = [None] * len(sent_text)
    for w_idx, (_, st, ed) in enumerate(spans):
        for pos in range(st, ed):
            char2word[pos] = w_idx
    last = -1
    for i, v in enumerate(char2word):
        if v is None:
            char2word[i] = last
        else:
            last = v
    return char2word


class SadatTrainer:
    def __init__(
            self,
            model,
            tokenizer,
            optimizer,
            scheduler,
            max_train_steps,
            gradient_accumulation_steps=1,
            fp16=False,
            adv_steps=2,
            adv_lr=1e-1,
            adv_max_norm=1e-1,
            adv_epsilon=0.1,
            adv_temp=1.0,
            adv_init_var=1e-2,
            grad_threshold=0.1,
            sparse_tau=0.1,
            cand_topk=20,
            output_dir: str = "./outputs",
            task_name: str = "task",
            id2label: Optional[Dict] = None,
            reg_lambda_entropy=0.01,
            reg_lambda_kl=0.01,
            logits_temperature=1.1,
            label_smoothing=0.0,
            temp_schedule=None,
            temp_warmup_steps=None,
            clean_loss_weight=0.3,
            adv_loss_weight=0.7
    ):
        # Initialize weights and modules
        self.adv_loss_weight = adv_loss_weight
        self.clean_loss_weight = clean_loss_weight
        self.model = model
        self.model_uw = model.module if hasattr(model, "module") else model
        self.word_embeddings = getattr(self.model_uw,
                                       self.model_uw.config.model_type.split("-")[0]).embeddings.word_embeddings
        self.device = model.device
        self.fp16 = fp16
        if self.fp16:
            self.scaler = GradScaler()
        self.optimizer = optimizer
        self.scheduler = scheduler
        self.max_train_steps = max_train_steps
        self.gradient_accumulation_steps = gradient_accumulation_steps
        self.global_step = 0

        # Adversarial and regularization hyperparameters
        self.adv_steps = adv_steps
        self.adv_lr = adv_lr
        self.adv_max_norm = adv_max_norm
        self.adv_temp = adv_temp
        self.adv_epsilon = adv_epsilon
        self.adv_init_var = adv_init_var
        self.grad_threshold = grad_threshold
        self.tau = sparse_tau
        self.cand_topk = cand_topk
        os.makedirs(output_dir, exist_ok=True)
        self.output_dir = output_dir
        fname = f"{task_name}_adv_samples.tsv"
        self.adv_path = os.path.join(self.output_dir, fname)
        self.id2label = id2label or {}

        # Create file for adv samples
        if not os.path.exists(self.adv_path):
            with open(self.adv_path, "w", encoding="utf-8") as f:
                f.write("guid\ttrue_label\torig_pred\torig_text\tadv_text\tadv_pred\n")

        # Regularization weights
        self.reg_lambda_entropy = reg_lambda_entropy
        self.reg_lambda_kl = reg_lambda_kl
        self.logits_temperature = logits_temperature
        self.label_smoothing = label_smoothing
        self.temp_schedule = temp_schedule
        self.temp_warmup_steps = temp_warmup_steps or (max_train_steps // 10)
        self.initial_logits_temperature = logits_temperature
        # Temperature scheduler
        if temp_schedule == 'linear':
            self.temp_scheduler = self._linear_temp_schedule
        elif temp_schedule == 'cosine':
            self.temp_scheduler = self._cosine_temp_schedule
        else:
            self.temp_scheduler = None

    def _linear_temp_schedule(self, step):
        if step < self.temp_warmup_steps:
            return self.initial_logits_temperature * (step / self.temp_warmup_steps)
        return self.initial_logits_temperature

    def _cosine_temp_schedule(self, step):
        if step < self.temp_warmup_steps:
            return self.initial_logits_temperature * (1 - math.cos(math.pi * step / self.temp_warmup_steps)) / 2
        return self.initial_logits_temperature

    def label_smoothing_loss(self, logits, target, epsilon, num_classes):
        log_probs = F.log_softmax(logits, dim=-1)
        one_hot = torch.zeros_like(logits).scatter(1, target.unsqueeze(1), 1)
        smoothed_target = one_hot * (1 - epsilon) + epsilon / num_classes
        loss = -(smoothed_target * log_probs).sum(dim=-1).mean()
        return loss

    def step(self, input_data):
        self.model.train()
        train_loss = 0
        train_step = 0

        for step, batch in enumerate(tqdm(input_data, desc="Iteration")):
            batch = tuple(t.to(self.device) for t in batch)
            input_ids, input_mask, segment_ids, labels = batch

            # Update temperature
            if self.temp_scheduler:
                current_logits_temp = self.temp_scheduler(self.global_step)
            else:
                current_logits_temp = self.logits_temperature

            # Get embeddings
            inputs_embeds = self.word_embeddings(input_ids)

            # Forward clean inputs
            if self.fp16:
                with autocast():
                    outputs = self.model(inputs_embeds=inputs_embeds,
                                         attention_mask=input_mask,
                                         token_type_ids=segment_ids,
                                         labels=labels,
                                         output_hidden_states=True)
            else:
                outputs = self.model(inputs_embeds=inputs_embeds,
                                     attention_mask=input_mask,
                                     token_type_ids=segment_ids,
                                     labels=labels,
                                     output_hidden_states=True)

            # Compute clean loss
            logits = outputs.logits
            scaled_logits = logits / current_logits_temp
            if self.label_smoothing > 0:
                loss_fct = lambda logit: self.label_smoothing_loss(logit, labels, self.label_smoothing, logit.size(-1))
            else:
                loss_fct = lambda logit: torch.nn.CrossEntropyLoss()(logit, labels)
            loss_clean = loss_fct(scaled_logits)

            # Extract context vector
            ctxr = outputs.hidden_states[-1][:, 0]

            # Initialize adversarial perturbation
            delta = torch.zeros_like(inputs_embeds, requires_grad=True)
            loss_ptb = 0.0

            # Adversarial updates
            for j in range(self.adv_steps):
                if self.fp16:
                    with autocast():
                        out_ptb = self.model(inputs_embeds=inputs_embeds + delta,
                                             attention_mask=input_mask,
                                             token_type_ids=segment_ids,
                                             labels=labels,
                                             output_hidden_states=True)
                else:
                    out_ptb = self.model(inputs_embeds=inputs_embeds + delta,
                                         attention_mask=input_mask,
                                         token_type_ids=segment_ids,
                                         labels=labels,
                                         output_hidden_states=True)

                adv_logits = out_ptb.logits
                scaled_adv_logits = adv_logits / current_logits_temp
                loss_adv = loss_fct(scaled_adv_logits)
                ctxr_ptb = out_ptb.hidden_states[-1][:, 0]

                # Semantic similarity regularization (cosine)
                loss_ptb = loss_adv - cosine_similarity(ctxr_ptb.unsqueeze(0), ctxr.unsqueeze(0)).mean() * self.adv_temp

                # KL regularization
                if current_logits_temp > 1.0:
                    orig_probs = F.softmax(logits / current_logits_temp, dim=-1)
                    temp_reg = F.kl_div(F.log_softmax(adv_logits / current_logits_temp, dim=-1),
                                        orig_probs,
                                        reduction='batchmean')
                    loss_ptb = loss_ptb + self.reg_lambda_kl * temp_reg

                # Entropy regularization
                adv_probs = F.softmax(adv_logits / current_logits_temp, dim=-1)
                entropy = -(adv_probs * torch.log(adv_probs + 1e-8)).sum(dim=-1).mean()
                loss_ptb = loss_ptb + self.reg_lambda_entropy * entropy

                if j == self.adv_steps - 1:
                    break

                # Compute gradient and sparse update
                delta_grad, = torch.autograd.grad(loss_ptb, delta, retain_graph=True)
                grad_norm = delta_grad.norm(p=2, dim=-1)
                mask = (grad_norm > self.grad_threshold).float().unsqueeze(-1)
                update = self.adv_lr * delta_grad / (grad_norm.unsqueeze(-1) + 1e-8)
                delta = (delta + update * mask).detach()
                delta.requires_grad_()

            # Project perturbations to discrete tokens
            # ... (unchanged multi-distribution candidate pool logic) ...

            # Combine clean and adversarial loss
            loss = self.clean_loss_weight * loss_clean + self.adv_loss_weight * loss_ptb
            if self.fp16:
                self.scaler.scale(loss).backward()
            else:
                loss.backward()

            train_loss += loss.item()
            train_step += 1

            if (step + 1) % self.gradient_accumulation_steps == 0 or step == len(input_data) - 1:
                if self.fp16:
                    self.scaler.unscale_(self.optimizer)
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    self.optimizer.step()
                self.scheduler.step()
                self.model.zero_grad()
                self.global_step += 1

            if self.global_step >= self.max_train_steps:
                break

        return train_loss, train_step, current_logits_temp
